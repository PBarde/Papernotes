# Proximal Policy Optimization Algorithms (PPO)

#### Schulman *et al.* (2017)

In this work, 

![algorithm](algorithm.PNG)
